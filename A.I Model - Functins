import os
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"
import tensorflow as tf
from tensorflow.keras import layers
import pathlib
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt

resize_height = 64
resize_width = 64
batch_size = 2

# Path Directory for TRAINING DATA
train_directory = 'data/edge/train/'  # Make new file for this directory
ds_train = tf.data.Dataset.list_files(str(pathlib.Path(train_directory + '*.png')))

# Path Directory for TESTING DATA
test_directory = 'data/edge/test/'  # Make new file for this directory
ds_test = tf.data.Dataset.list_files(str(pathlib.Path(test_directory + '*.png')))


# Process to get path of pictures
def process_path(file_path, training=True):
    image = tf.io.read_file(file_path)
    image = tf.image.decode_png(image, channels=1)
    image = tf.image.resize(image, [resize_height, resize_width])
    label = tf.strings.split(file_path, os.sep)
    label = tf.strings.substr(label[-1], pos=0, len=1)
    label = tf.strings.to_number(label, out_type=tf.int64)
    return image, label


# OVERALL PROCESSING OF ALL PHOTOS
ds_train = ds_train.map(lambda x: process_path(x, training=True)).batch(batch_size)
ds_test = ds_test.map(lambda x: process_path(x, training=False)).batch(batch_size)


# Model for training the A.I
model = tf.keras.Sequential(
    [
        layers.Input((resize_height, resize_width, 1)),
        layers.Conv2D(16, 3, padding="same", activation='relu'),
        layers.Conv2D(32, 3, padding="same", activation='relu'),
        layers.MaxPooling2D(),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dense(2, activation='softmax')
    ]
)

model.compile(
    optimizer=tf.keras.optimizers.Adam(),
    loss=[tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)],
    metrics=["accuracy"],
)

model.fit(ds_train, epochs=15, verbose=2)

# Evaluate the model
predictions = model.predict(ds_test)
print(predictions)

# Function to preprocess the image
def preprocess_image(image_path):
    image = tf.io.read_file(image_path)
    image = tf.image.decode_png(image, channels=1)
    image = tf.image.resize(image, [resize_height, resize_width])
    image = tf.expand_dims(image, axis=0)  # Add batch dimension
    return image


# Load images and make predictions
def load_and_predict(directory):
    image_paths = list(pathlib.Path(directory).glob('*.png'))
    predictions = []
    images = []

    for image_path in image_paths:
        processed_image = preprocess_image(str(image_path))
        prediction = model.predict(processed_image)
        predicted_label = tf.argmax(prediction, axis=1).numpy()[0]
        predictions.append(predicted_label)
        images.append(image_path)

    return images, predictions

# Plot the results using matplotlib
def plot_results(images, predictions):
    plt.figure(figsize=(20, 10))
    for i, (image_path, prediction) in enumerate(zip(images, predictions)):
        plt.subplot(2, len(images)//2 + len(images)%2, i + 1)
        image = Image.open(image_path).convert("L")
        plt.imshow(image, cmap='gray')
        plt.title('Not Oily' if prediction == 0 else 'Oily')
        plt.axis('off')
    plt.tight_layout()


    # Create a pie chart for prediction percentages
    unique, counts = np.unique(predictions, return_counts=True)
    labels = ['Not Oily', 'Oily']
    counts_dict = dict(zip(unique, counts))
    counts_list = [counts_dict.get(i, 0) for i in range(len(labels))]
    total = sum(counts_list)
    percentages = [count / total * 100 for count in counts_list]

    plt.figure(figsize=(8, 6))
    plt.pie(percentages, labels=labels, autopct='%1.1f%%', colors=['blue', 'green'])
    plt.title('Prediction Percentages')
    plt.show()


# Load images and predict
images, predictions = load_and_predict(test_directory)

# Plot the results
plot_results(images, predictions)
